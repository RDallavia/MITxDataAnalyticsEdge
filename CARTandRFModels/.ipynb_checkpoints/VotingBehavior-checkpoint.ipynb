{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Do People Vote?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Study\n",
    "\"In August 2006 three researchers (Alan Gerber and Donald Green of Yale University, and Christopher Larimer of the University of Northern Iowa) carried out a large scale field experiment in Michigan, USA to test the hypothesis that one of the reasons people vote is social, or extrinsic, pressure.\" \n",
    "\n",
    "\"The researchers grouped about 344,000 voters into different groups randomly - about 191,000 voters were a \"control\" group, and the rest were categorized into one of four \"treatment\" groups. These five groups correspond to five binary variables in the dataset.\"\n",
    "\n",
    "(source: MITx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Variables\n",
    "\n",
    "**\"Civic Duty\" (variable civicduty)** group members were sent a note saying \"DO YOUR CIVIC DUTY - VOTE!\"\n",
    "\n",
    "**\"Hawthorne Effect\" (variable hawthorne)** group members were sent a the \"Civic Duty\" message plus the message \"YOU ARE BEING STUDIED\" and told their voting behavior would be examined via public records.\n",
    "\n",
    "**\"Self\" (variable self)** group members were sent the \"Civic Duty\" message, in addition to recent voting records for everyone in their home. Furthermore, an updated message stated that updated voting records for the household would be sent after the election.\n",
    "\n",
    "**\"Neighbors\" (variable neighbors)** group members received the same message the \"Self\" group, accompanied not only by the household voting records, but also those of neighbors.  This was done to maximize social pressure.\n",
    "\n",
    "**\"Control\" (variable control)** group members received and represented the typical voter.\n",
    "\n",
    "Additional variables include **sex** (0 for male, 1 for female), **yob (year of birth)**, and **the dependent variable voting** (1 if they voted, 0 otherwise).\n",
    "\n",
    "(source: MITx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerber = read.csv(\"gerber.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t344084 obs. of  8 variables:\n",
      " $ sex      : int  0 1 1 1 0 1 0 0 1 0 ...\n",
      " $ yob      : int  1941 1947 1982 1950 1951 1959 1956 1981 1968 1967 ...\n",
      " $ voting   : int  0 0 1 1 1 1 1 0 0 0 ...\n",
      " $ hawthorne: int  0 0 1 1 1 0 0 0 0 0 ...\n",
      " $ civicduty: int  1 1 0 0 0 0 0 0 0 0 ...\n",
      " $ neighbors: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ self     : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ control  : int  0 0 0 0 0 1 1 1 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "str(gerber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      sex              yob           voting         hawthorne    \n",
       " Min.   :0.0000   Min.   :1900   Min.   :0.0000   Min.   :0.000  \n",
       " 1st Qu.:0.0000   1st Qu.:1947   1st Qu.:0.0000   1st Qu.:0.000  \n",
       " Median :0.0000   Median :1956   Median :0.0000   Median :0.000  \n",
       " Mean   :0.4993   Mean   :1956   Mean   :0.3159   Mean   :0.111  \n",
       " 3rd Qu.:1.0000   3rd Qu.:1965   3rd Qu.:1.0000   3rd Qu.:0.000  \n",
       " Max.   :1.0000   Max.   :1986   Max.   :1.0000   Max.   :1.000  \n",
       "   civicduty        neighbors          self           control      \n",
       " Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n",
       " 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:0.0000  \n",
       " Median :0.0000   Median :0.000   Median :0.0000   Median :1.0000  \n",
       " Mean   :0.1111   Mean   :0.111   Mean   :0.1111   Mean   :0.5558  \n",
       " 3rd Qu.:0.0000   3rd Qu.:0.000   3rd Qu.:0.0000   3rd Qu.:1.0000  \n",
       " Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(gerber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 31.59% of individuals in the data set voted, but which of our four \"treatment groups\" voted the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "voter_percent = function(df, x, y, table_cell){\n",
    "    \n",
    "    # Input: Dataframe as variable, x and y as column\n",
    "    # names (strings), and the number of the cell of interest\n",
    "    # as an int [1,4].\n",
    "    #\n",
    "    # Output: Yields the value of a single \n",
    "    # cell in a proportionate table as a percentage.\n",
    "    \n",
    "    base_table = table(df[[x]], df[[y]])\n",
    "    cross_table = prop.table(base_table, margin=1)\n",
    "    return (round((cross_table[[table_cell]]*100),2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"32.24% of the hawthorne group voted.\"\n",
      "[1] \"31.45% of the civicduty group voted.\"\n",
      "[1] \"37.79% of the neighbors group voted.\"\n",
      "[1] \"34.52% of the self group voted.\"\n",
      "[1] \"29.66% of the control group voted.\"\n"
     ]
    }
   ],
   "source": [
    "columns = c(colnames(gerber)[4:8])\n",
    "for (i in columns){\n",
    "    print(paste(voter_percent(gerber, i, \"voting\", 4), \"% of the \", i ,\" group voted.\", sep=\"\"))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data above indicate the largest percentage of study participants who actually voted were in the \"neighbors\" cohort. This suggests heightened social pressure may increase one's propensity to vote.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Models ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Logistic Approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We constructed a logistic model using the entire response vector (i.e., voting) as the dependent variable and the four \"treatment groups\" (i.e., civicduty, hawthorne, self, neighbors) as independent variables. While we won't use this for preditive purposes, the results were interesting: all four groups were attended by coefficients that were highly significant. Restated, while voting behavior appears to be related to treatment-group membership, no specific treatment group stood out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit1 = glm(voting ~ civicduty + hawthorne + self + neighbors, data=gerber, family=binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = voting ~ civicduty + hawthorne + self + neighbors, \n",
       "    family = binomial, data = gerber)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-0.9744  -0.8691  -0.8389   1.4586   1.5590  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error  z value Pr(>|z|)    \n",
       "(Intercept) -0.863358   0.005006 -172.459  < 2e-16 ***\n",
       "civicduty    0.084368   0.012100    6.972 3.12e-12 ***\n",
       "hawthorne    0.120477   0.012037   10.009  < 2e-16 ***\n",
       "self         0.222937   0.011867   18.786  < 2e-16 ***\n",
       "neighbors    0.365092   0.011679   31.260  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 429238  on 344083  degrees of freedom\n",
       "Residual deviance: 428090  on 344079  degrees of freedom\n",
       "AIC: 428100\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(logit1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Predictive Logistic Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by creating a baseline model against which we can compare the performance of future models we may build. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The most common observation is: 0.\"\n",
      "[1] \"Its frequency is: 235388.\"\n",
      "[1] \"The accuracy of our baseline model is 68.41%.\"\n"
     ]
    }
   ],
   "source": [
    "baseline = function(df, response_var) {\n",
    "    # Input: Name of data frame as variable & name of binary response\n",
    "    # variable as string.\n",
    "    #\n",
    "    # Output: The most common observation, its raw frequency, and the\n",
    "    # accuracy of the baseline model, which future models must beat.\n",
    "    \n",
    "    table1 = table(df[[response_var]])\n",
    "    \n",
    "    if (table1[[1]] > table1[[2]]) {\n",
    "        \n",
    "        accuracy = table1[[1]]/sum(table1[[1]],table1[[2]])\n",
    "        most_common = names(table1[1])\n",
    "        print(paste(\"The most common observation is: \", most_common,\".\", sep=\"\"))\n",
    "        print(paste(\"Its frequency is: \", table1[[1]],\".\", sep=\"\"))\n",
    "    \n",
    "    } else {\n",
    "        \n",
    "        accuracy = table1[[2]]/sum(table1[[1]],table1[[2]])\n",
    "        most_common = names(table1[2])\n",
    "        print(paste(\"The most common observation is: \", most_common,\".\", sep=\"\"))\n",
    "        print(paste(\"Its frequency is: \", table1[[2]],\".\", sep=\"\"))\n",
    "    \n",
    "    }\n",
    "    \n",
    "    return(print(paste(\"The accuracy of our baseline model is \", round(accuracy*100,2), \"%\",\".\", sep=\"\")))\n",
    "}\n",
    "\n",
    "baseline(gerber, 'voting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a prediction we'll split our data into training and test sets.  Given that we'd like our training and test sets to reflect a balanced representation of the data, we will go with a 70/30 split, as the baseline model revealed the response variable was 0 in approximately 70% of cases.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in install.packages(\"caTools\"):\n",
      "“installation of package ‘caTools’ had non-zero exit status”Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"caTools\")\n",
    "library(caTools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1024)\n",
    "split = sample.split(gerber$voting, .70)\n",
    "train = subset(gerber, split=TRUE)\n",
    "test = subset(gerber, split=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit2 = glm(voting ~ civicduty + hawthorne + self + neighbors, data=train, family=binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = voting ~ civicduty + hawthorne + self + neighbors, \n",
       "    family = binomial, data = train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-0.9744  -0.8691  -0.8389   1.4586   1.5590  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error  z value Pr(>|z|)    \n",
       "(Intercept) -0.863358   0.005006 -172.459  < 2e-16 ***\n",
       "civicduty    0.084368   0.012100    6.972 3.12e-12 ***\n",
       "hawthorne    0.120477   0.012037   10.009  < 2e-16 ***\n",
       "self         0.222937   0.011867   18.786  < 2e-16 ***\n",
       "neighbors    0.365092   0.011679   31.260  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 429238  on 344083  degrees of freedom\n",
       "Residual deviance: 428090  on 344079  degrees of freedom\n",
       "AIC: 428100\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(logit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary data from our logistic model constructed from the training set is strikingly similar to that which was produced by the logistic model trained on the entire data set. Let's see how this model performs in- and out-of-sample relative to our baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       " 0.2966  0.2966  0.2966  0.3159  0.3224  0.3779 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>0</dt>\n",
       "\t\t<dd>0.31</dd>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>0.32</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[0] 0.31\n",
       "\\item[1] 0.32\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "0\n",
       ":   0.311\n",
       ":   0.32\n",
       "\n"
      ],
      "text/plain": [
       "   0    1 \n",
       "0.31 0.32 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# identifying type as resonse tells R to return probabilities\n",
    "predictTrain = predict(logit2, type=\"response\")\n",
    "summary(predictTrain)\n",
    "(round(tapply(predictTrain, train$voting, mean),2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on both the data above, it looks like our model predicts a higher probability of voting (32%) -- just above the mean -- for participants in the treatment groups than it does for non-voting (31%) respondents. While the spread is not as wide as one would hope for or expect, neither is the spread between the mean and the 3rd quartile. Assessing the accuracy of our in-sample training model will provide further insight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = function(df, observed_y, predicted_y, threshold) {\n",
    "    \n",
    "    # Input: dataframe, response variable name as string, vector of \n",
    "    # predicted values, threshold value\n",
    "    # \n",
    "    # Output: Confusion matrix to assess model performance\n",
    "    \n",
    "    mtx=table(df[[observed_y]], predicted_y > threshold)\n",
    "    \n",
    "    return (addmargins(mtx))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>FALSE</th><th scope=col>TRUE</th><th scope=col>Sum</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0</th><td>134513</td><td>100875</td><td>235388</td></tr>\n",
       "\t<tr><th scope=row>1</th><td> 56730</td><td> 51966</td><td>108696</td></tr>\n",
       "\t<tr><th scope=row>Sum</th><td>191243</td><td>152841</td><td>344084</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & FALSE & TRUE & Sum\\\\\n",
       "\\hline\n",
       "\t0 & 134513 & 100875 & 235388\\\\\n",
       "\t1 &  56730 &  51966 & 108696\\\\\n",
       "\tSum & 191243 & 152841 & 344084\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | FALSE | TRUE | Sum |\n",
       "|---|---|---|---|\n",
       "| 0 | 134513 | 100875 | 235388 |\n",
       "| 1 |  56730 |  51966 | 108696 |\n",
       "| Sum | 191243 | 152841 | 344084 |\n",
       "\n"
      ],
      "text/plain": [
       "     \n",
       "      FALSE  TRUE   Sum   \n",
       "  0   134513 100875 235388\n",
       "  1    56730  51966 108696\n",
       "  Sum 191243 152841 344084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmtx=confusion_mtx(train, 'voting', predictTrain, .3)\n",
    "cmtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Based on the confusion matrix, the accuracy of the model is 54%\"\n"
     ]
    }
   ],
   "source": [
    "confusion_accuracy = function(confusion_matrix) {\n",
    "    \n",
    "    # Input: 3x3 or 3x2 confusion matrix\n",
    "    #\n",
    "    # Output: Message stating the accuracy of the model based on the data\n",
    "    # contained in the matrix.\n",
    "    \n",
    "    if (dim(confusion_matrix)[1] == dim(confusion_matrix)[2]) {\n",
    "        \n",
    "        accuracy = (confusion_matrix[[1]] + confusion_matrix[[5]])/confusion_matrix[[9]]\n",
    "    \n",
    "    } else if (dim(confusion_matrix)[1] > dim(confusion_matrix)[2]) {\n",
    "        \n",
    "        accuracy = (confusion_matrix[[1]])/confusion_matrix[[6]]\n",
    "    }\n",
    "    \n",
    "    return (print(paste(\"Based on the confusion matrix, the accuracy of the model is \", round(accuracy,2)*100, \"%\", sep=\"\")))\n",
    "}\n",
    "\n",
    "confusion_accuracy(cmtx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 54% accuracy rate is hardly impressive considering our basline model had an accuracy of 68.41%. We will change out threshold to see if we can improve our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>FALSE</th><th scope=col>Sum</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>0</th><td>235388</td><td>235388</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>108696</td><td>108696</td></tr>\n",
       "\t<tr><th scope=row>Sum</th><td>344084</td><td>344084</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & FALSE & Sum\\\\\n",
       "\\hline\n",
       "\t0 & 235388 & 235388\\\\\n",
       "\t1 & 108696 & 108696\\\\\n",
       "\tSum & 344084 & 344084\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | FALSE | Sum |\n",
       "|---|---|---|\n",
       "| 0 | 235388 | 235388 |\n",
       "| 1 | 108696 | 108696 |\n",
       "| Sum | 344084 | 344084 |\n",
       "\n"
      ],
      "text/plain": [
       "     \n",
       "      FALSE  Sum   \n",
       "  0   235388 235388\n",
       "  1   108696 108696\n",
       "  Sum 344084 344084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmtx2=confusion_mtx(train, 'voting', predictTrain, .5)\n",
    "cmtx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Based on the confusion matrix, the accuracy of the model is 68%\"\n"
     ]
    }
   ],
   "source": [
    "confusion_accuracy(cmtx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting our threshold drastically improved our accuracy from 54% to 68% and enabled us to surpass the baseline prediction, albeit by a a slim margin. As models go, it's not terribly strong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
